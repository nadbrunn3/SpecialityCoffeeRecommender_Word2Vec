{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48d0063-2e9f-451b-88a5-15da7c7021a3",
   "metadata": {},
   "source": [
    "# Translating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89fb9f56-df62-413e-ba5e-c9a50a41ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import deepl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaac635-7408-434d-8283-381d5424299c",
   "metadata": {},
   "source": [
    "## Deepl API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bfc0828-8d8e-49bd-ba0e-dfe646ee9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_yaml(filepath):\n",
    "#     with open(filepath, 'r') as f: \n",
    "#         return yaml.safe_load(f)\n",
    "\n",
    "# config =  read_yaml('../config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5cc5bfe3-9ec5-4bb3-a268-b86d041950e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = deepl.Translator('f18d00ef-8c6f-9521-fe63-770be4d69a49:fx')\n",
    "\n",
    "# Testing: \n",
    "result = translator.translate_text(\"Hello, world!\", target_lang=\"FR\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902ba423-6ecc-414d-aede-ed6cca81af92",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82abdf-ccc2-4e04-b65e-ce89d67b2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(col):\n",
    "    '''\n",
    "    Translates columns to english: \n",
    "    Input: Column to be translated\n",
    "    Output: Returns a list of translated column    \n",
    "    '''\n",
    "    trans = []\n",
    "    for idx, val in enumerate(col):\n",
    "        trans.append(translator.translate_text(val, target_lang=\"EN-US\"))    \n",
    "    return trans\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449bb270-255f-44a0-bb54-d96d9dc5f244",
   "metadata": {},
   "source": [
    "#### 19grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7759c736-c699-4e76-95f0-47f4071ee4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grams = pd.read_csv('../data_clean/19grams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94fe3251-aae2-48c3-aa03-7f1b56bbb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonizing Column Names:\n",
    "grams.rename(columns = {'coffee_variety': 'variety',\n",
    "                       'review': 'flavour'}, inplace=True)\n",
    "\n",
    "# Tanslating columns and adding translated columns to df\n",
    "grams['flavour_en'] = translate(grams['flavour'])\n",
    "grams['origin_en'] = translate(grams['coffee_country'])\n",
    "\n",
    "# Picking columns relevant for the Model: \n",
    "df = grams[['coffee_title', 'origin_en', 'flavour_en']]\n",
    "df.columns = ['coffee', 'origin', 'flavour'] # Renaming columns\n",
    "\n",
    "#df.to_csv('../data_flav_optimized_en/19grams.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a591520-8a0b-40e8-90ac-e7afeaafa65b",
   "metadata": {},
   "source": [
    "#### coffee friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1d86dde4-4858-498f-a77f-cd1f9df0371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('../data_clean/coffee_friend.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "edf5ab81-cbf5-44a5-bacc-f68b5112728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanslating columns and adding translated columns to df\n",
    "file['flavour_en'] = translate(file.review_text)\n",
    "file['coffee'] = translate(file.coffee_title)\n",
    "\n",
    "# Picking columns relevant for the Model: \n",
    "df = file[['coffee', 'coffee_country', 'coffee_region', 'variety', 'production', 'roast', 'flavour_en']]\n",
    "\n",
    "# Renaming columns\n",
    "df.rename(columns={'coffee_country': 'origin',\n",
    "                  'coffee_region': 'region',\n",
    "                  'production': 'process',\n",
    "                  'flavour_en': 'flavour'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "752f6da5-3086-4f12-b2e3-0292f8b4cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('../data_flav_optimized_en/coffee_friends.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc20ed-25ee-48a5-b6de-893b0d4311ac",
   "metadata": {},
   "source": [
    "#### Kaffeezentral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "10c51fdf-ee37-439f-923b-9b1eda1e054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('../data_clean/kaffeezentrale.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c83e3dcc-e63c-4661-981b-4abc501d4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanslating columns and adding translated columns to df\n",
    "file['flavour_en'] = translate(file.review_text)\n",
    "file['coffee'] = translate(file.coffee_title)\n",
    "\n",
    "# Picking columns relevant for the Model: \n",
    "df = file[['coffee', 'flavour_en']]\n",
    "\n",
    "# Renaming columns\n",
    "df.columns = ['coffee', 'flavour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4cab5685-95f9-4a7b-a53a-283e12724bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('../data_flav_optimized_en/kaffeezentrale.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bfedb-57ba-4745-80bc-29b20b619c04",
   "metadata": {},
   "source": [
    "#### Kaffeothek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "cb5d4b98-1deb-4c99-95e9-c70cebd7040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('../data_clean/kaffeothek.csv')\n",
    "\n",
    "# manually correcting translation error\n",
    "file.loc[file.roast_level == 'Hell', 'roast_level'] = 'leicht' \n",
    "\n",
    "# Tanslating columns and adding translated columns to df\n",
    "file['origin'] = translate(file.coffee_origin_country)\n",
    "file['flavour'] = translate(file.review_text)\n",
    "file['roast'] = translate(file.roast_level)\n",
    "\n",
    "# manually correcting translation error\n",
    "file.loc[file.roast == 'easy', 'roast'] = 'light'\n",
    "\n",
    "# Picking columns relevant for the Model: \n",
    "df = file[['coffee_title', 'origin', 'coffee_variety', 'roast', 'flavour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "02c9b1d8-f562-4135-a8f7-e35988843f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROC was scrapped later in the data cleaning process: \n",
    "## therefore the 2 dataframes (df, proc) need to be harmonized and concatenated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1df1c2cd-c180-4b53-b17b-3ce0450727d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "proc = pd.read_csv('../data_raw/othek_process.csv')\n",
    "\n",
    "# Dropping columns from the new df that are not representated in the original df: \n",
    "\n",
    "proc.drop(2, axis=0, inplace=True)\n",
    "proc.drop(42, axis=0, inplace=True)\n",
    "proc.drop(proc[proc.coffee == 'Suchan, Santos'].index, axis=0, inplace=True)\n",
    "proc.drop(proc[proc.coffee == 'Stoll, Honduras, Bio'].index, axis=0, inplace=True)\n",
    "\n",
    "proc.coffee = [i.replace('\\n', '').strip() for i in proc.coffee]\n",
    "\n",
    "# Checking if same Coffees are represented in both dfs:\n",
    "list(zip(proc.coffee.tolist(), df.coffee_title.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "14c6fed3-50ce-4410-b773-f82f6fca1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.process= proc.process.fillna('unknown')\n",
    "proc.process = [i.replace('\\n', '').strip() for i in proc.process]\n",
    "proc = proc.reset_index()\n",
    "\n",
    "# Replacing df column with new df column because it carries more information:\n",
    "df['coffee'] = proc.coffee\n",
    "\n",
    "#dropping odl column:\n",
    "df.drop('coffee_title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "8a273ea5-e0b7-4a01-916b-3a42caf944c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\nwashed                                                                     12\n",
       "\\nnatural                                                                     2\n",
       "Finca Hartmann                                                                2\n",
       "Enciso                                                                        1\n",
       "\\nfermentiert                                                                 1\n",
       "Fazienda Passeio, Adolfo Henrique Vieira Ferreira                             1\n",
       "Fazenda Pedra Preta                                                           1\n",
       "La Serrania                                                                   1\n",
       "Aman Adinew                                                                   1\n",
       "Justin Musabyiama                                                             1\n",
       "Cooperative San Carlos                                                        1\n",
       "Finca Lovaina                                                                 1\n",
       "Bedessa Washing Station                                                       1\n",
       "Finca La Maria                                                                1\n",
       "Finca El Silencio, Robinson Rivera                                            1\n",
       "\\nfermentiert, washed                                                         1\n",
       "Vamay Montana                                                                 1\n",
       "Rodriguez                                                                     1\n",
       "Bombe Abore Washing Station                                                   1\n",
       "Charles Murimi                                                                1\n",
       "Fazenda Jaguara                                                               1\n",
       "Finca Auromar                                                                 1\n",
       "Bio                                                                           1\n",
       "Kooperative ACRIM,  Kooperative COMSA,  Fazendas Klem                         1\n",
       "CEPCO Coop,  WOFFA Coop                                                       1\n",
       "Fazenda Capim Branco,  Kooperative COMSA,  Kooperative ACRIM,  Rukullakta     1\n",
       "Gora Kone                                                                     1\n",
       "Finca Bonita Springs                                                          1\n",
       "\\nwashed, natural                                                             1\n",
       "Fazenda Capim Branco,  Kooperative APPAECE,  Rukullakta,                      1\n",
       "Fazenda Nossa Senhora de Fatima                                               1\n",
       "\\nnatural, washed                                                             1\n",
       "Boji Cooperative                                                              1\n",
       "\\nfermentiert, natural                                                        1\n",
       "Fazenda Santa Lucia                                                           1\n",
       "Finca El Pacayalito,  Beneficio Las Americas                                  1\n",
       "Omar Rodriguez                                                                1\n",
       "Asociaci√≥n de Mujeres Cafetera Plan Mil                                       1\n",
       "Finca San Jose                                                                1\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "7ed947f8-c44c-441f-8bd3-9beadc866fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting all PROCESS terms from REGION:\n",
    "ml = ['natural, washed', 'fermentiert, natural', 'washed, naturla', 'fermentiert', 'natural', 'washed']\n",
    "proc.region = proc.region.fillna('unknown')\n",
    "proc.region = [val.replace('\\n', '').strip().lower() for val in proc.region]\n",
    "\n",
    "# Including the terms in PROCESS column:\n",
    "for idx, i in enumerate(proc.region):\n",
    "    proc['process'][idx] = np.where(i in ml, i, proc['process'][idx])\n",
    "\n",
    "proc.reg = proc.reg.fillna('unknown')\n",
    "proc.reg = [val.replace('\\n', '').strip().lower() for val in proc.reg]\n",
    "for idx, i in enumerate(proc.reg):\n",
    "    proc['process'][idx] = np.where(i in ml, i, proc['process'][idx])\n",
    "\n",
    "#Reduction PROCESS to washed, natural, anaearob, unknown\n",
    "proc['process'] = np.where(proc.process == 'natural, washed', 'natural', proc.process)\n",
    "proc['process'] = np.where(proc.process == 'washed, natural', 'washed', proc.process)\n",
    "proc['process'] = np.where(proc.process == 'semi-washed', 'washed', proc.process)\n",
    "proc['process'] = np.where(proc.process == 'anaerobic fermentiert', 'anaerob', proc.process)\n",
    "proc['process'] = np.where(proc.process == 'washed, entkoffeiniert', 'washed', proc.process)\n",
    "proc['process'] = np.where(proc.process == 'fermentiert, natural', 'anaerob', proc.process)\n",
    "proc['process'] = np.where(proc.process == 'fermentiert', 'anaerob', proc.process)\n",
    "proc['process'] = np.where(proc.process == 'Sugar Cane Decaf', 'unknown', proc.process)\n",
    "\n",
    "# Stripping values:\n",
    "proc['process'] = [str(i).strip() for i in proc.process]\n",
    "\n",
    "# Creating final df:\n",
    "df_new = df[['coffee', 'origin', 'coffee_variety', 'roast', 'flavour']]\n",
    "df_new['process'] = proc.process\n",
    "df_new.rename(columns={'coffee_variety': 'variety'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "0c595ef7-a5e2-44ff-ac6d-09383e51a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually translating a left out value:\n",
    "df_new.origin[0] = 'Indonesia, Brazil, India'\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "93b6fc97-b7db-49c4-b731-dcf230c2af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.to_csv('../data_flav_optimized_en/kaffeothek_inkl.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf74ae2-19a9-4fa4-9183-7123db4ae2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
